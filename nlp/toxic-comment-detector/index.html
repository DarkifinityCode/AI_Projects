<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Toxic Comment Detector</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js"></script>
</head>
<body>
  <header>
    <h1>Toxic Comment Detector</h1>
    <p class="muted">Check if a comment is toxic or safe</p>
  </header>

  <main>
    <textarea id="textInput" placeholder="Type a comment here..." rows="5"></textarea>
    <button id="analyzeBtn">Analyze</button>
    <div id="result" class="output"></div>
  </main>

  <footer>
    <small>© 2025 Aseem Shukla — Toxic Comment Detector (TensorFlow.js)</small>
  </footer>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity"></script>

  <script>
    async function detectToxicity(text) {
      const threshold = 0.85; // Confidence threshold: adjust to your needs.
      const model = await toxicity.load(threshold);
      const predictions = await model.classify([text]);
      console.log(predictions); // Contains per-label toxicity results.
      return predictions;
    }

    detectToxicity("You suck!")
      .then(pred => {
        console.log(JSON.stringify(pred, null, 2));
      });
  </script>

  <script src="script.js"></script>
</body>
</html>
